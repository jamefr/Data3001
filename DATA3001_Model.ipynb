{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3bed3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors_to_remove = [\"destinationMacAddress\", \"sourceMacAddress\", \"egressInterface\", \"ingressInterface\", \"initialTCPFlags\", \n",
    "                    \"reverseInitialTCPFlags\", \"reverseTcpUrgTotalCount\", \"reverseUnionTCPFlags\", \"silkAppLabel\", \n",
    "                    \"tcpSequenceNumber\", \"tcpUrgTotalCount\", \"unionTCPFlags\", \"vlanId\", \"sourceIPv4Address\", \n",
    "                    \"destinationIPv4Address\", \"reverseTcpSequenceNumber\", \"observationDomainId\", \"reverseStandardDeviationInterarrivalTime\",\n",
    "                    \"reverseStandardDeviationPayloadLength\", \"reverseSmallPacketCount\", \"reverseNonEmptyPacketCount\",\n",
    "                    \"reverseMaxPacketSize\", \"reverseLargePacketCount\", \"reverseFirstNonEmptyPacketSize\", \"reverseDataByteCount\",\n",
    "                    \"reverseBytesPerPacket\", \"reverseAverageInterarrivalTime\", \"collectorName\"]\n",
    "\n",
    "regressor_has_null = [\"protocolIdentifier\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052d0a8a",
   "metadata": {},
   "source": [
    "This code will just read in the downloaded test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb80f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_json('train_df_noGoogle.json', lines=True)\n",
    "df2 = pd.read_json('train_google.json', lines=True)\n",
    "train_df = pd.concat([df1,df2],ignore_index=True)\n",
    "test_df = pd.read_json('test_df.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14986a33",
   "metadata": {},
   "source": [
    "This code will individually read the raw json data and create a train response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f0cf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in file amazon_echo_gen2.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file au_network_camera.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file au_wireless_adapter.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file bitfinder_awair_breathe_easy.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file candy_house_sesami_wi-fi_access_point.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file i-o_data_qwatch.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file irobot_roomba.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file jvc_kenwood_cu-hb1.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file jvc_kenwood_hdtv_ip_camera.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file line_clova_wave.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file link_japan_eremote.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file mouse_computer_room_hub.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file nature_remo.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file panasonic_doorphone.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file philips_hue_bridge.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file planex_camera_one_shot!.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file planex_smacam_outdoor.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file planex_smacam_pantilt.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file powerelectric_wi-fi_plug.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file qrio_hub.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file sony_bravia.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file sony_network_camera.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file sony_smart_speaker.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n",
      "in file xiaomi_mijia_led.json\n",
      "part 1\n",
      "part 2\n",
      "part 3\n",
      "part 4\n",
      "part 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import *\n",
    "import gc\n",
    "#spark = SparkSession.builder.appName(\"cleanData\").getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "folder_path = 'C:\\\\Users\\\\Priyash Shah\\\\Downloads\\\\DATA3001 Project Data\\\\Extracted Data'\n",
    "data_lengths = []\n",
    "# Get all files in the directory\n",
    "files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "#df = spark.createDataFrame(spark.sparkContext.emptyRDD(),schema)\n",
    "train_df = pd.DataFrame()\n",
    "for file in files:\n",
    "    \n",
    "    file_path = folder_path+'\\\\'+file\n",
    "    data = []\n",
    "    length = 0\n",
    "    ### TEMP\n",
    "    dataset = open(file_path)\n",
    "    print(f\"in file {file}\")\n",
    "    # Read file line by line based on date\n",
    "    for line in dataset:\n",
    "        obj = json.loads(line)\n",
    "        \n",
    "        if 'flows' in obj:\n",
    "           \n",
    "            dateflow = obj['flows']['flowEndMilliseconds']\n",
    "            if dateflow > \"2019-08-26\":\n",
    "                break\n",
    "            length += 1    \n",
    "            data.append(obj['flows'])\n",
    "        else:\n",
    "            break\n",
    "    print(f\"part 1\")\n",
    "    response = re.sub('([^.]*).json$', r'\\1', file)\n",
    "    data_info = (response, length)        \n",
    "    data_lengths.append(data_info)\n",
    "    print(f\"part 2\")\n",
    "    # Assuming data is already loaded\n",
    "    temp_df = pd.DataFrame(data)\n",
    "    # Removing regressors we are not interested in\n",
    "    print(f\"part 3\")\n",
    "    for regressors in regressors_to_remove:\n",
    "        if regressors in temp_df.columns: \n",
    "            temp_df = temp_df.drop(columns=regressors)\n",
    "    print(f\"part 4\")\n",
    "\n",
    "    # Sampling\n",
    "    temp_df = temp_df.dropna().sample(n = 5000, random_state=69)\n",
    "    print(f\"part 5\")\n",
    "    # print(temp_df.columns)\n",
    "    # Dropping columns\n",
    "    \n",
    "    # Dropping rows with all NaN values in the specified columns\n",
    "    #for regressors in regressor_has_null:\n",
    "    #    temp_df = temp_df.dropna(how='all', subset=[regressors])\n",
    "    temp_df['response'] = response    \n",
    "    train_df = pd.concat([train_df, temp_df], ignore_index=True)\n",
    "    # Explicitly delete temp_df and free up memory\n",
    "    del temp_df\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e70aad5",
   "metadata": {},
   "source": [
    "Does the same as above but for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83d64ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in file amazon_echo_gen2.json\n",
      "in file au_network_camera.json\n",
      "in file au_wireless_adapter.json\n",
      "in file bitfinder_awair_breathe_easy.json\n",
      "in file candy_house_sesami_wi-fi_access_point.json\n",
      "in file google_home_gen1.json\n",
      "in file i-o_data_qwatch.json\n",
      "in file irobot_roomba.json\n",
      "in file jvc_kenwood_cu-hb1.json\n",
      "in file jvc_kenwood_hdtv_ip_camera.json\n",
      "in file line_clova_wave.json\n",
      "in file link_japan_eremote.json\n",
      "in file mouse_computer_room_hub.json\n",
      "in file nature_remo.json\n",
      "in file panasonic_doorphone.json\n",
      "in file philips_hue_bridge.json\n",
      "in file planex_camera_one_shot!.json\n",
      "in file planex_smacam_outdoor.json\n",
      "in file planex_smacam_pantilt.json\n",
      "in file powerelectric_wi-fi_plug.json\n",
      "in file qrio_hub.json\n",
      "in file sony_bravia.json\n",
      "in file sony_network_camera.json\n",
      "in file sony_smart_speaker.json\n",
      "in file xiaomi_mijia_led.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import *\n",
    "import gc\n",
    "\n",
    "folder_path = 'C:\\\\Users\\\\Priyash Shah\\\\Downloads\\\\DATA3001 Project Data\\\\Extracted Data'\n",
    "data_lengths = []\n",
    "# Get all files in the directory\n",
    "files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "#df = spark.createDataFrame(spark.sparkContext.emptyRDD(),schema)\n",
    "test_df = pd.DataFrame()\n",
    "for file in files:\n",
    "    print(f\"in file {file}\")\n",
    "    file_path = folder_path+'\\\\'+file\n",
    "    data = []\n",
    "    length = 0\n",
    "    ### TEMP\n",
    "    dataset = open(file_path)\n",
    "    \n",
    "    # Read file line by line based on date\n",
    "    for line in dataset:\n",
    "        obj = json.loads(line)\n",
    "        \n",
    "        if 'flows' in obj:\n",
    "           \n",
    "            dateflow = obj['flows']['flowEndMilliseconds']\n",
    "            if dateflow > \"2019-09-10\":\n",
    "                break\n",
    "            if dateflow > \"2019-08-27\":\n",
    "                length += 1    \n",
    "                data.append(obj['flows'])\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    response = re.sub('([^.]*).json$', r'\\1', file)\n",
    "    data_info = (response, length)        \n",
    "    data_lengths.append(data_info)\n",
    "    \n",
    "    # Assuming data is already loaded\n",
    "    temp_df = pd.DataFrame(data)\n",
    "    \n",
    "    # Removing regressors we are not interested in\n",
    "    for regressors in regressors_to_remove:\n",
    "        if regressors in temp_df.columns: \n",
    "            temp_df = temp_df.drop(columns=regressors)\n",
    "\n",
    "    # Sampling\n",
    "    temp_df = temp_df.dropna().sample(n = 1000, random_state=69)\n",
    "\n",
    "    # print(temp_df.columns)\n",
    "    # Dropping columns\n",
    "    \n",
    "    # Dropping rows with all NaN values in the specified columns\n",
    "    for regressors in regressor_has_null:\n",
    "        temp_df = temp_df.dropna(how='all', subset=[regressors])\n",
    "    temp_df['response'] = response    \n",
    "    test_df = pd.concat([test_df, temp_df], ignore_index=True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cfa97a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flowDurationMilliseconds</th>\n",
       "      <th>reverseFlowDeltaMilliseconds</th>\n",
       "      <th>protocolIdentifier</th>\n",
       "      <th>sourceTransportPort</th>\n",
       "      <th>packetTotalCount</th>\n",
       "      <th>octetTotalCount</th>\n",
       "      <th>flowAttributes</th>\n",
       "      <th>destinationTransportPort</th>\n",
       "      <th>reversePacketTotalCount</th>\n",
       "      <th>reverseOctetTotalCount</th>\n",
       "      <th>...</th>\n",
       "      <th>nonEmptyPacketCount</th>\n",
       "      <th>dataByteCount</th>\n",
       "      <th>averageInterarrivalTime</th>\n",
       "      <th>firstNonEmptyPacketSize</th>\n",
       "      <th>largePacketCount</th>\n",
       "      <th>maxPacketSize</th>\n",
       "      <th>standardDeviationPayloadLength</th>\n",
       "      <th>standardDeviationInterarrivalTime</th>\n",
       "      <th>bytesPerPacket</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009</td>\n",
       "      <td>0.009</td>\n",
       "      <td>2</td>\n",
       "      <td>53406</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>47580</td>\n",
       "      <td>2</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>840</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>560</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2</td>\n",
       "      <td>42680</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2</td>\n",
       "      <td>17525</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0.576</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>40445</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>576</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1785.302</td>\n",
       "      <td>0.118</td>\n",
       "      <td>1</td>\n",
       "      <td>456</td>\n",
       "      <td>242</td>\n",
       "      <td>14144</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>124</td>\n",
       "      <td>9072</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>4464</td>\n",
       "      <td>7407</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "      <td>4</td>\n",
       "      <td>7213</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.578</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>57819</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>578</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.584</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>41411</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>584</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0.595</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>35980</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>595</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       flowDurationMilliseconds  reverseFlowDeltaMilliseconds  \\\n",
       "0                         0.009                         0.009   \n",
       "1                         0.003                         0.000   \n",
       "2                         0.036                         0.000   \n",
       "3                         0.010                         0.010   \n",
       "4                         0.030                         0.030   \n",
       "...                         ...                           ...   \n",
       "24995                     0.576                         0.000   \n",
       "24996                  1785.302                         0.118   \n",
       "24997                     0.578                         0.000   \n",
       "24998                     0.584                         0.000   \n",
       "24999                     0.595                         0.000   \n",
       "\n",
       "       protocolIdentifier  sourceTransportPort  packetTotalCount  \\\n",
       "0                       2                53406                 1   \n",
       "1                       1                47580                 2   \n",
       "2                       0                    8                10   \n",
       "3                       2                42680                 1   \n",
       "4                       2                17525                 1   \n",
       "...                   ...                  ...               ...   \n",
       "24995                   2                40445                 2   \n",
       "24996                   1                  456               242   \n",
       "24997                   2                57819                 2   \n",
       "24998                   2                41411                 2   \n",
       "24999                   2                35980                 2   \n",
       "\n",
       "       octetTotalCount  flowAttributes  destinationTransportPort  \\\n",
       "0                   71               0                        53   \n",
       "1                  111               0                       443   \n",
       "2                  840               1                         0   \n",
       "3                   75               0                        53   \n",
       "4                   71               0                        53   \n",
       "...                ...             ...                       ...   \n",
       "24995              156               1                       137   \n",
       "24996            14144               0                        80   \n",
       "24997              156               1                       137   \n",
       "24998              156               1                       137   \n",
       "24999              156               1                       137   \n",
       "\n",
       "       reversePacketTotalCount  reverseOctetTotalCount  ...  \\\n",
       "0                            1                     139  ...   \n",
       "1                            0                       0  ...   \n",
       "2                            0                       0  ...   \n",
       "3                            1                     139  ...   \n",
       "4                            1                     139  ...   \n",
       "...                        ...                     ...  ...   \n",
       "24995                        0                       0  ...   \n",
       "24996                      124                    9072  ...   \n",
       "24997                        0                       0  ...   \n",
       "24998                        0                       0  ...   \n",
       "24999                        0                       0  ...   \n",
       "\n",
       "       nonEmptyPacketCount  dataByteCount  averageInterarrivalTime  \\\n",
       "0                        1             43                        0   \n",
       "1                        1             31                        3   \n",
       "2                       10            560                        4   \n",
       "3                        1             47                        0   \n",
       "4                        1             43                        0   \n",
       "...                    ...            ...                      ...   \n",
       "24995                    2            100                      576   \n",
       "24996                  121           4464                     7407   \n",
       "24997                    2            100                      578   \n",
       "24998                    2            100                      584   \n",
       "24999                    2            100                      595   \n",
       "\n",
       "       firstNonEmptyPacketSize  largePacketCount  maxPacketSize  \\\n",
       "0                           43                 0             43   \n",
       "1                           31                 0             31   \n",
       "2                           56                 0             56   \n",
       "3                           47                 0             47   \n",
       "4                           43                 0             43   \n",
       "...                        ...               ...            ...   \n",
       "24995                       50                 0             50   \n",
       "24996                       32                 1            624   \n",
       "24997                       50                 0             50   \n",
       "24998                       50                 0             50   \n",
       "24999                       50                 0             50   \n",
       "\n",
       "       standardDeviationPayloadLength  standardDeviationInterarrivalTime  \\\n",
       "0                                   0                                  0   \n",
       "1                                   0                                  0   \n",
       "2                                   0                                  2   \n",
       "3                                   0                                  0   \n",
       "4                                   0                                  0   \n",
       "...                               ...                                ...   \n",
       "24995                               0                                  0   \n",
       "24996                               4                               7213   \n",
       "24997                               0                                  0   \n",
       "24998                               0                                  0   \n",
       "24999                               0                                  0   \n",
       "\n",
       "       bytesPerPacket  response  \n",
       "0                  43         0  \n",
       "1                  31         0  \n",
       "2                  56         0  \n",
       "3                  47         0  \n",
       "4                  43         0  \n",
       "...               ...       ...  \n",
       "24995              50        24  \n",
       "24996              36        24  \n",
       "24997              50        24  \n",
       "24998              50        24  \n",
       "24999              50        24  \n",
       "\n",
       "[25000 rows x 24 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099185f2",
   "metadata": {},
   "source": [
    "Cleans the data for XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffa63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\"flowStartMilliseconds\", \"flowEndMilliseconds\",'firstEightNonEmptyPacketDirections']\n",
    "for regressors in columns_to_remove:\n",
    "    if regressors in train_df.columns:\n",
    "        train_df = train_df.drop(columns=regressors)\n",
    "        test_df = test_df.drop(columns=regressors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7953719a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the response to numeric values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_df['response'] = le.fit_transform(train_df['response'])\n",
    "test_df['response'] = le.fit_transform(test_df['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd142b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Variables into category\n",
    "columns_categorical = [\"flowAttributes\", \"protocolIdentifier\", \"ipClassOfService\", \"flowEndReason\",\n",
    "                      'reverseFlowAttributes']\n",
    "\n",
    "\n",
    "for regressors in columns_categorical:\n",
    "    train_df[regressors] = train_df[regressors].astype('category')\n",
    "    test_df[regressors] = test_df[regressors].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a46440fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columns_categorical:\n",
    "    train_df[col] = train_df[col].cat.codes\n",
    "    test_df[col] = test_df[col].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfbcf6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125000 entries, 0 to 124999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   flowDurationMilliseconds           125000 non-null  float64\n",
      " 1   reverseFlowDeltaMilliseconds       125000 non-null  float64\n",
      " 2   protocolIdentifier                 125000 non-null  int8   \n",
      " 3   sourceTransportPort                125000 non-null  int64  \n",
      " 4   packetTotalCount                   125000 non-null  int64  \n",
      " 5   octetTotalCount                    125000 non-null  int64  \n",
      " 6   flowAttributes                     125000 non-null  int8   \n",
      " 7   destinationTransportPort           125000 non-null  int64  \n",
      " 8   reversePacketTotalCount            125000 non-null  int64  \n",
      " 9   reverseOctetTotalCount             125000 non-null  int64  \n",
      " 10  reverseFlowAttributes              125000 non-null  int8   \n",
      " 11  ipClassOfService                   125000 non-null  int8   \n",
      " 12  flowEndReason                      125000 non-null  int8   \n",
      " 13  smallPacketCount                   125000 non-null  int64  \n",
      " 14  nonEmptyPacketCount                125000 non-null  int64  \n",
      " 15  dataByteCount                      125000 non-null  int64  \n",
      " 16  averageInterarrivalTime            125000 non-null  int64  \n",
      " 17  firstNonEmptyPacketSize            125000 non-null  int64  \n",
      " 18  largePacketCount                   125000 non-null  int64  \n",
      " 19  maxPacketSize                      125000 non-null  int64  \n",
      " 20  standardDeviationPayloadLength     125000 non-null  int64  \n",
      " 21  standardDeviationInterarrivalTime  125000 non-null  int64  \n",
      " 22  bytesPerPacket                     125000 non-null  int64  \n",
      " 23  response                           125000 non-null  int32  \n",
      "dtypes: float64(2), int32(1), int64(16), int8(5)\n",
      "memory usage: 18.2 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddced843",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "937f4e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4118\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "response = ['response']\n",
    "predictors = [x for x in list(train_df.columns) if x not in response]\n",
    "\n",
    "X = train_df[predictors]\n",
    "y = train_df[response]\n",
    "X_test = test_df[predictors]\n",
    "y_test = test_df[response]\n",
    "#label = train_df['response']\n",
    "#dtrain = xgb.DMatrix(train_df, label=label, enable_categorical=True)\n",
    "# Instantiate an XGBClassifier\n",
    "model = xgb.XGBClassifier(objective ='multi:softprob', \n",
    "                          num_class = 19,\n",
    "                          colsample_bytree = 0.3, \n",
    "                          learning_rate = 0.1,\n",
    "                          max_depth = 10, \n",
    "                          alpha = 1, \n",
    "                          n_estimators = 50)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e0c8f",
   "metadata": {},
   "source": [
    "### Exploring prediction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9b58aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_arr = np.ravel(y_test)\n",
    "# Step 2: Create a DataFrame with true labels and predicted labels\n",
    "results_df = pd.DataFrame({'True': y_test_arr, 'Predicted': y_pred})\n",
    "\n",
    "# Step 3: Compare the true and predicted labels to find mismatches\n",
    "results_df['Correct'] = results_df['True'] == results_df['Predicted']\n",
    "\n",
    "# Step 4: Extract indices of incorrectly classified instances\n",
    "incorrect_indices = results_df[results_df['Correct'] == False].index.tolist()\n",
    "\n",
    "# Now `incorrect_indices` holds the indices of the incorrectly classified instances\n",
    "#print(\"Indices of incorrectly classified instances:\", incorrect_indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d1c5e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It should be response    0\n",
      "Name: 0, dtype: int32, I am getting 0\n"
     ]
    }
   ],
   "source": [
    "row = 0\n",
    "prediction_int = y_test.iloc[row]\n",
    "print(f'It should be {prediction_int}, I am getting {y_pred[row]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df675b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52821815, 0.00714703, 0.03455031, ..., 0.00629136, 0.01075714,\n",
       "        0.00702013],\n",
       "       [0.7807144 , 0.00256663, 0.00435964, ..., 0.00200704, 0.00305754,\n",
       "        0.00264425],\n",
       "       [0.91762847, 0.00104874, 0.00098997, ..., 0.00118892, 0.00112028,\n",
       "        0.00098989],\n",
       "       ...,\n",
       "       [0.02109229, 0.03403796, 0.01524978, ..., 0.04164699, 0.01014183,\n",
       "        0.03341097],\n",
       "       [0.02103613, 0.02710547, 0.01372556, ..., 0.04248632, 0.0093953 ,\n",
       "        0.04124414],\n",
       "       [0.01933529, 0.02646217, 0.01408833, ..., 0.04258097, 0.00934198,\n",
       "        0.03754492]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = model.predict_proba(X_test)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c74c888f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52821815, 0.00714703, 0.03455031, 0.00774228, 0.00679514,\n",
       "       0.20508993, 0.00740229, 0.00716077, 0.05794402, 0.00720267,\n",
       "       0.009235  , 0.00659496, 0.00622814, 0.0069524 , 0.00965795,\n",
       "       0.00919403, 0.00615403, 0.0070845 , 0.01066438, 0.00879017,\n",
       "       0.00732048, 0.0188028 , 0.00629136, 0.01075714, 0.00702013],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities[row,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c21b5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper parameter tuning\n",
    "model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "param_grid = {\n",
    "    'n_estimators': [50,100],\n",
    "    'learning_rate': [0.1,0.2],\n",
    "    'max_depth': [5,10],\n",
    "    'alpha': [1,2]\n",
    "}\n",
    "model = xgb.XGBClassifier(use_label_encoder=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0834da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [1, 2], &#x27;learning_rate&#x27;: [0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [5, 10], &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [1, 2], &#x27;learning_rate&#x27;: [0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [5, 10], &#x27;n_estimators&#x27;: [50, 100]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'alpha': [1, 2], 'learning_rate': [0.1, 0.2],\n",
       "                         'max_depth': [5, 10], 'n_estimators': [50, 100]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(model, param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "988e5769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 2, 'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 50}\n",
      "Test accuracy: 0.4669473684210526\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c79ea8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 = amazon_echo_gen2\n",
      "1 = au_network_camera\n",
      "2 = au_wireless_adapter\n",
      "3 = bitfinder_awair_breathe_easy\n",
      "4 = candy_house_sesami_wi-fi_access_point\n",
      "5 = google_home_gen1\n",
      "6 = i-o_data_qwatch\n",
      "7 = irobot_roomba\n",
      "8 = jvc_kenwood_cu-hb1\n",
      "9 = jvc_kenwood_hdtv_ip_camera\n",
      "10 = line_clova_wave\n",
      "11 = link_japan_eremote\n",
      "12 = mouse_computer_room_hub\n",
      "13 = nature_remo\n",
      "14 = panasonic_doorphone\n",
      "15 = philips_hue_bridge\n",
      "16 = planex_camera_one_shot!\n",
      "17 = planex_smacam_outdoor\n",
      "18 = planex_smacam_pantilt\n",
      "19 = powerelectric_wi-fi_plug\n",
      "20 = qrio_hub\n",
      "21 = sony_bravia\n",
      "22 = sony_network_camera\n",
      "23 = sony_smart_speaker\n",
      "24 = xiaomi_mijia_led\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "conversion = np.arange(0,25)\n",
    "decoded_category = le.inverse_transform(conversion)\n",
    "for i in conversion:\n",
    "    print(f'{i} = {decoded_category[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ac40de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Decision Tree Accuracy: 41.18%\n",
      " \n",
      "class by class:\n",
      "amazon_echo_gen2, accuracy = 652%\n",
      "au_network_camera, accuracy = 112%\n",
      "au_wireless_adapter, accuracy = 731%\n",
      "bitfinder_awair_breathe_easy, accuracy = 152%\n",
      "candy_house_sesami_wi-fi_access_point, accuracy = 49%\n",
      "google_home_gen1, accuracy = 978%\n",
      "i-o_data_qwatch, accuracy = 935%\n",
      "irobot_roomba, accuracy = 60%\n",
      "jvc_kenwood_cu-hb1, accuracy = 811%\n",
      "jvc_kenwood_hdtv_ip_camera, accuracy = 95%\n",
      "line_clova_wave, accuracy = 361%\n",
      "link_japan_eremote, accuracy = 40%\n",
      "mouse_computer_room_hub, accuracy = 992%\n",
      "nature_remo, accuracy = 1%\n",
      "panasonic_doorphone, accuracy = 880%\n",
      "philips_hue_bridge, accuracy = 255%\n",
      "planex_camera_one_shot!, accuracy = 984%\n",
      "planex_smacam_outdoor, accuracy = 105%\n",
      "planex_smacam_pantilt, accuracy = 93%\n",
      "powerelectric_wi-fi_plug, accuracy = 551%\n",
      "qrio_hub, accuracy = 249%\n",
      "sony_bravia, accuracy = 896%\n",
      "sony_network_camera, accuracy = 146%\n",
      "sony_smart_speaker, accuracy = 104%\n",
      "xiaomi_mijia_led, accuracy = 63%\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "between = 1000\n",
    "i = 0\n",
    "print(f\"Gradient Boosted Decision Tree Accuracy: {accuracy*100}%\\n \\nclass by class:\")\n",
    "while(between <= 25000):\n",
    "    unique, counts = np.unique(y_pred[between-1000:between], return_counts=True)\n",
    "    i_count = np.sum(y_pred[between-1000:between] == i)\n",
    "    tot = np.sum(y_pred[:] == i)\n",
    "    #tot += i_count\n",
    "    percentage = i_count\n",
    "    print(f'{decoded_category[i]}, accuracy = {percentage}%')\n",
    "    #print(f'{i} = {decoded_category[i]}, we are accurate {percentage}% amount of times\\n{dict(zip(unique, counts))}')\n",
    "    between += 1000\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b73dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8452039a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a5598c6",
   "metadata": {},
   "source": [
    "### Threshold without standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f64193f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get class probabilities\n",
    "probabilities = model.predict_proba(X_test)\n",
    "\n",
    "# Apply threshold\n",
    "# This will create a 2D array of boolean values where True indicates\n",
    "# that the corresponding probability exceeds the threshold\n",
    "threshold_met = probabilities > 0.5\n",
    "\n",
    "# Create an array to store your predictions with a default value for unclassified\n",
    "# Assuming -1 is the marker for unclassified instances\n",
    "predictions = np.full((probabilities.shape[0],), -1)\n",
    "\n",
    "for i, instance in enumerate(threshold_met):\n",
    "    # Check if any probability meets the threshold\n",
    "    if any(instance):\n",
    "        # Get the index of the max probability above the threshold\n",
    "        predictions[i] = np.argmax(probabilities[i])\n",
    "\n",
    "# Now 'predictions' contains the class with the highest probability above the threshold\n",
    "# or -1 for those where no probability exceeded the threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29816364",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1f3dbb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83838cc2",
   "metadata": {},
   "source": [
    "### Threshold with standardising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d85a10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### standardising the probabilities based on individual class means and std deviations\n",
    "import pandas as pd\n",
    "probabilities = model.predict_proba(X_test)\n",
    "prob = pd.DataFrame(probabilities)\n",
    "mean_prob = prob.mean(axis=0)\n",
    "std_deviation = prob.std(axis=0)\n",
    "\n",
    "mean_prob = np.ravel(mean_prob)\n",
    "std_deviation = np.ravel(std_deviation)\n",
    "mean_reduced_prob = (probabilities - mean_prob) / std_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5586795",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "z_score_50_percent = (0.5 - mean_prob) / std_deviation\n",
    "threshold = mean_reduced_prob > z_score_50_percent\n",
    "predictions = np.full((probabilities.shape[0],), -1)\n",
    "for i, instance in enumerate(threshold):\n",
    "    # Check if any probability meets the threshold\n",
    "    if any(instance):\n",
    "        # Get the index of the max probability above the threshold\n",
    "        predictions[i] = np.argmax(mean_reduced_prob[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40e730ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped: 14366, total = 25000, percent = 57.464000000000006%\n"
     ]
    }
   ],
   "source": [
    "dropped = (predictions == -1).sum()\n",
    "total = len(predictions)\n",
    "print(f'dropped: {dropped}, total = {total}, percent = {dropped/total*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ee80d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyash Shah\\AppData\\Local\\Temp\\ipykernel_12704\\3339173291.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction_cert['Correct'] = prediction_cert['True'] == prediction_cert['Predicted']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10058"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_test_arr = np.ravel(y_test)\n",
    "# Step 2: Create a DataFrame with true labels and predicted labels\n",
    "results_df = pd.DataFrame({'True': y_test_arr, 'Predicted': predictions})\n",
    "\n",
    "classified = results_df['Predicted'] != -1\n",
    "\n",
    "prediction_cert = results_df[classified]\n",
    "\n",
    "prediction_cert['Correct'] = prediction_cert['True'] == prediction_cert['Predicted']\n",
    "true_count = prediction_cert['Correct'].sum()\n",
    "true_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "95a521fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10634, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_cert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "057e96f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9458341169832613"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10058/10634"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a2205",
   "metadata": {},
   "source": [
    "### Class by class accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3eb01989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mouse_computer_room_hub': (992, 992),\n",
       " 'planex_camera_one_shot!': (984, 984),\n",
       " 'i-o_data_qwatch': (931, 937),\n",
       " 'sony_bravia': (885, 900),\n",
       " 'panasonic_doorphone': (849, 850),\n",
       " 'jvc_kenwood_cu-hb1': (795, 797),\n",
       " 'au_wireless_adapter': (723, 723),\n",
       " 'amazon_echo_gen2': (625, 627),\n",
       " 'google_home_gen1': (573, 855),\n",
       " 'powerelectric_wi-fi_plug': (549, 552),\n",
       " 'sony_smart_speaker': (541, 788),\n",
       " 'line_clova_wave': (302, 303),\n",
       " 'qrio_hub': (239, 239),\n",
       " 'philips_hue_bridge': (236, 244),\n",
       " 'bitfinder_awair_breathe_easy': (149, 149),\n",
       " 'sony_network_camera': (146, 146),\n",
       " 'au_network_camera': (108, 110),\n",
       " 'planex_smacam_outdoor': (105, 105),\n",
       " 'planex_smacam_pantilt': (86, 86),\n",
       " 'jvc_kenwood_hdtv_ip_camera': (78, 80),\n",
       " 'candy_house_sesami_wi-fi_access_point': (46, 46),\n",
       " 'link_japan_eremote': (41, 45),\n",
       " 'irobot_roomba': (39, 40),\n",
       " 'xiaomi_mijia_led': (36, 36),\n",
       " 'failed': (0, 14366)}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "conversion = np.arange(0,25)\n",
    "decoded_category = le.inverse_transform(conversion)\n",
    "y_test_arr = np.ravel(y_test)\n",
    "\n",
    "def classByClassAccuracy(predictions, actual):\n",
    "    ind = 0\n",
    "    classes = {}\n",
    "    for j in predictions:\n",
    "        if j == -1:\n",
    "            i = 'failed'\n",
    "        else: \n",
    "            i = decoded_category[j]\n",
    "        if i in classes.keys():\n",
    "            \n",
    "            if i == decoded_category[actual[ind]]:\n",
    "                classes[i][\"count\"] += 1\n",
    "            classes[i][\"total\"] += 1\n",
    "        else:\n",
    "            \n",
    "            if i == decoded_category[actual[ind]]:\n",
    "                classes[i] = {\"count\":1, \"total\":1}\n",
    "            else:\n",
    "                classes[i] = {\"count\":0, \"total\":1}\n",
    "        \n",
    "        ind += 1\n",
    " \n",
    "    results = {}\n",
    "    for k in classes.keys():\n",
    "        results[k] = (classes[k][\"count\"], classes[k][\"total\"])\n",
    " \n",
    "    return dict(sorted(results.items(), key=lambda x:x[1], reverse=True))\n",
    "class_acc = classByClassAccuracy(predictions, y_test_arr)\n",
    "class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ba71097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for j in predictions:\n",
    "    i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92af6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ce57f87",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d5ae5be",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['flowAttributes'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m columns_categorical \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflowAttributes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprotocolIdentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mipClassOfService\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflowEndReason\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreverseFlowAttributes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m regressors \u001b[38;5;129;01min\u001b[39;00m columns_categorical:\n\u001b[1;32m----> 7\u001b[0m     train_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(train_df, columns\u001b[38;5;241m=\u001b[39m[regressors], prefix\u001b[38;5;241m=\u001b[39mregressors)\n\u001b[0;32m      8\u001b[0m     test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(test_df, columns\u001b[38;5;241m=\u001b[39m[regressors], prefix\u001b[38;5;241m=\u001b[39mregressors)\n",
      "File \u001b[1;32m~\\Downloads\\Anaconda\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:146\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m data[columns]\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name):\n",
      "File \u001b[1;32m~\\Downloads\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\Downloads\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\Downloads\\Anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   6129\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['flowAttributes'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Converting Variables into category\n",
    "columns_categorical = [\"flowAttributes\", \"protocolIdentifier\", \"ipClassOfService\", \"flowEndReason\",\n",
    "                      'reverseFlowAttributes']\n",
    "\n",
    "\n",
    "for regressors in columns_categorical:\n",
    "    train_df = pd.get_dummies(train_df, columns=[regressors], prefix=regressors)\n",
    "    test_df = pd.get_dummies(test_df, columns=[regressors], prefix=regressors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a42756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically remove inconsistent columns/predictors\n",
    "\n",
    "for regressors in test_df.columns:\n",
    "    if regressors not in train_df.columns:\n",
    "         test_df = test_df.drop(columns=regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dd5a620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually\n",
    "\n",
    "category = ['ipClassOfService_0xd0']\n",
    "for regressors in category:\n",
    "    if regressors in train_df.columns:\n",
    "        train_df = train_df.drop(columns=regressors)\n",
    "    if regressors in test_df.columns:\n",
    "        test_df = test_df.drop(columns=regressors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d60e9ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priyash Shah\\Downloads\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "response = ['response']\n",
    "predictors = [x for x in list(train_df.columns) if x not in response]\n",
    "\n",
    "X = train_df[predictors]\n",
    "y = train_df[response]\n",
    "X_test = test_df[predictors]\n",
    "y_test = test_df[response]\n",
    "forest1 = RandomForestClassifier(criterion='entropy', bootstrap=True, n_estimators = 400)\n",
    "forest1 = forest1.fit(X, y)\n",
    "res = forest1.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac4d4a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amazon_echo_gen2'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['response'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c46aa939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 0.44042105263157894\n",
      "me:      0.44042105263157894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracies = accuracy_score(y_test, res)\n",
    "count = 0\n",
    "total = 0\n",
    "for k in res:\n",
    "    if k == y_test['response'][total]:\n",
    "        count +=1\n",
    "    total += 1\n",
    "\n",
    "print(f\"sklearn: {accuracies}\\nme:      {count/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8779919f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
